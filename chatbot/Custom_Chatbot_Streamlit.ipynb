{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Utu9AjE0lZa6"
      },
      "outputs": [],
      "source": [
        "\n",
        "!curl https://ollama.ai/install.sh | sh # Install Ollama AI\n",
        "!nohup ollama serve & # Start Ollama AI service\n",
        "!pip install ollama # Install Ollama Python client\n",
        "!ollama pull llama2 #install model\n",
        "!pip install streamlit langchain_community\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jawHcVgGVWN7"
      },
      "outputs": [],
      "source": [
        "!pip install langchain\n",
        "!pip install docx2txt\n",
        "!pip install tiktoken\n",
        "!ollama pull nomic-embed-text\n",
        "!pip install chromadb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HAfXG3aSl75W"
      },
      "outputs": [],
      "source": [
        "!pip freeze >> requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fN66IUljY1Ab"
      },
      "outputs": [],
      "source": [
        "!pip install pyngrok"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Es4-CSkQh-5t"
      },
      "outputs": [],
      "source": [
        "!nohup ollama serve & # Start Ollama AI service\n",
        "!ollama pull llama2 #install model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "VBCz3iuIZYmh",
        "outputId": "891e86e4-d608-4e8c-af04-af2a17ae5bb4"
      },
      "outputs": [],
      "source": [
        "from pyngrok import ngrok\n",
        "import subprocess\n",
        "\n",
        "ngrok.set_auth_token('2aGUSiqfIzgKx0yh6XHaTX3G11f_5HRDp7atGGPtyxaiH91bc')\n",
        "\n",
        "port = 8501\n",
        "streamlit_process = subprocess.Popen([\"streamlit\", \"run\", \"/content/app.py\", f\"--server.port={port}\"])\n",
        "\n",
        "# Start ngrok tunnel for the Streamlit app\n",
        "ngrok_tunnel = ngrok.connect(addr=f'{port}')\n",
        "\n",
        "# Print the ngrok URL\n",
        "print(\"Ngrok Tunnel URL:\", ngrok_tunnel.public_url)\n",
        "\n",
        "# Block until Streamlit process finishes\n",
        "streamlit_process.wait()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
